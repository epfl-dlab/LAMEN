from uuid import uuid4
import os
import json
import csv
from dlabchain import AIMessage, SystemMessage, HumanMessage, ChatModel
from utils import get_api_key
from typing import Tuple
from omegaconf import DictConfig, OmegaConf

import logging
log = logging.getLogger("my-logger")


def create_agent_description(cfg: DictConfig):
    # TODO: think of sensible comparison axes, e.g., age, profession, sex, etc.
    agents = cfg["experiments"]["agents"]
    
    

def load_agent_description(agent_path) -> str:
    # TODO: load agent json and join into single string
    pass

class AgentSystemPrompt:
    def __init__(self, agent, game):
        pass


class NegotiationAgent:
    def __init__(self, agent_name=None, init_description=None,
                 msg_prompt=None, note_prompt=None,
                 msg_max_len=64, note_max_len=64,
                 msg_input_msg_history=-1, msg_input_note_history=-1,
                 note_input_msg_history=-1, note_input_note_history=-1,
                 model_name="gpt-4", model_provider='openai', model_key='OPENAI_API_KEY',
                 model_key_path='secrets.json', **kwargs) -> None:
        """
        Basic agent class
        agent_name
        init_description
        """
        # TODO: read description from data/agent_descriptions
        # self.init_description = load_agent_description(init_description)
        self.init_description = init_description # we load it in as a string unlike ^^^ 
        self.agent_name = str(uuid4()) if agent_name is None else agent_name

        # message params
        self.msg_prompt, self.msg_max_len = msg_prompt, msg_max_len
        self.msg_input_msg_history, self.msg_input_note_history = msg_input_msg_history, msg_input_note_history
        # notes params
        self.note_prompt, self.note_max_len = note_prompt, note_max_len
        self.note_input_msg_history, self.note_input_note_history = note_input_msg_history, note_input_note_history
        # generation parameters
        self.generation_parameters = kwargs
        # model
        api_key = get_api_key(fname=model_key_path, key=model_key)
        self.model = ChatModel(
            model_name=model_name, model_provider=model_provider, model_key=api_key,
            **self.generation_parameters
        )

        self.notes_history = []
        self.msg_history = []

    def generate_message(self, user_msg):
        # msg prompt structure:
        # system_msg(game, side, agent, issues) + user_msg(c_msg, note, msg, c_msg, note, prompt) -> agent_msg: msg
        context = [self.system_skeleton, HumanMessage(user_msg)]
        msg = self.model(context)
        self.msg_history.append((self.agent_name, msg))

        return msg

    def generate_note(self, user_msg):
        # note prompt structure:
        # system_msg(game, side, agent, issues) + user_msg(c_msg, note, msg, c_msg, prompt) --> agent_msg: note
        context = [self.system_skeleton, HumanMessage(user_msg)]
        note = self.model(context)
        self.notes_history.append((self.agent_name, note))

        return note

    def prepare_msg_note_input(self, c_msg_history: list) -> str:
        """
        Create input context for writing the next message/note.

        We loop backwards, only added context as far our 'memory' is allowed to go.
        :param c_msg_history: messages generated by the other agent
        :return: context msg
        """
        # more notes than messages indicates next generation will be a message
        msg = len(self.notes_history) > len(self.msg_history)
        max_len = max(len(self.notes_history), len(self.msg_history))

        max_m = self.msg_input_msg_history if msg else self.note_input_msg_history
        max_n = self.msg_input_note_history if msg else self.note_input_note_history

        neg_history = []
        for i in range(0, max_len):

            if msg and i < max_n and i < len(self.notes_history):
                neg_history.append(self.notes_history[-i])

            if i < max_m:
                if i < len(c_msg_history):
                    neg_history.append(c_msg_history[-i])
                if i < len(self.msg_history):
                    neg_history.append(self.msg_history[-i])

            if not msg and i < max_n and i < len(self.notes_history):
                neg_history.append(self.notes_history[-i])

            if i + 1 == max_len and max_len < len(c_msg_history):
                neg_history.append(c_msg_history[0])

        neg_history = neg_history[::-1]
        next_prompt = self.msg_prompt if msg else self.note_prompt

        user_msg = 'Below a transcript of the negotiations and your internal notes so far:\n'
        for (a, i) in neg_history:
            user_msg += f'[{a}] {i}\n'
        user_msg += next_prompt

        return user_msg

    def step(self, user_msg):
        # create mental note
        self.generate_note(user_msg)
        # create external message
        self.generate_message(user_msg)

    # likely, this could also be a function of the ChatModel() class
    def check_context_len_step(self) -> bool:
        # TODO: get token len of completion input (system_msg, msg_history, note_history, prev_game_history) + note/msg
        # NOTE: openai adds 8 tokens for any request
        # 1. enough context token space to generate note?
        # 2. enough context token space to generate msg?
        # not clear how to make a scalable approach to max token length across dif models
        got_space = True

        return got_space

    def get_settings(self):
        # TODO: return init settings for analysis / saving
        pass        
    
    def create_static_system_prompt(self, shared_description, side_description, issues_format):
        intial_story = shared_description +"\n"+ side_description +  "\nDescription of your qualities:\n" + self.init_description + "\n" + issues_format
        self.system_skeleton = SystemMessage(intial_story)
        print(intial_story)

    def get_issues_state(self) -> dict:
        # TODO: get latest issues_proposal from internal notes
        pass

    def __repr__(self):
        return f"{self.init_description}"


class NegotiationProtocol:
    """
    Run negotiations
    """
    def __init__(self, agents, game, start_agent_index=0, stop_condition='context_fill', max_rounds=1e6,
                 save_folder='data/results'):

        os.makedirs(save_folder, exist_ok=True)
        self.save_folder = save_folder

        self.max_rounds = max_rounds
        self.stop_condition = stop_condition
        self.game = game
        game_shared_description = game.description
        
        # get issues for each agent

        # move the agent order to respect start agent index
        self.agents = agents


        for i, agent in enumerate(agents):
            issues_format = game.format_all_issues(i)
            agent_side = self.game.sides[i][0]
            agent.create_static_system_prompt(game_shared_description, agent_side, issues_format)

    def run(self):
        # TODO: conduct rounds of negotiation until a stop_condition is hit
        #       after each respective agent step, call check_completion()
        completed = False
        num_rounds = 0
        while not completed:
            self.agents[0].step()
            completed = self.check_completion(num_rounds=num_rounds)
            self.save_results()

            if not completed:
                self.agents[1].step()
                completed = self.check_completion(num_rounds=num_rounds)
                self.save_results()

            num_rounds += 1

    def check_completion(self, num_rounds) -> bool:
        # 1. all issues are agreed upon
        # 2. max rounds reached
        # 3. ran out of context tokens
        #   -> a. stop
        #   -> b. drop history
        #   -> c. fancier stuff, e.g., memory bank search etc.
        completed = False
        # 1
        if self.compare_issues(return_issues=False):
            completed = True
        # 2
        if num_rounds >= self.max_rounds:
            completed = True
        # 3
        if not self.agents[0].check_context_len_step():
            completed = True
        if not self.agents[1].check_context_len_step():
            completed = True

        return completed

    def compare_issues(self, return_issues=False) -> Tuple[bool, dict]:
        is1 = self.agents[0].get_issues_state()
        is2 = self.agents[1].get_issues_state()

        is_keys = is2.keys()
        agreed_issues = [k for k in is_keys if is1.get(k) == is2.get(k)]
        agreed = len(agreed_issues) == len(is_keys)

        if return_issues:
            return agreed, agreed_issues

        return agreed

    def save_results(self):
        # TODO: save a csv or json row containing:
        # agent; round; note; message; issues_state; timestamp
        headers = ['agent', 'round', 'note', 'message', 'issues_state', 'timestamp']
        csv_path = os.path.join(self.save_folder, 'negotiation.csv')
        pass