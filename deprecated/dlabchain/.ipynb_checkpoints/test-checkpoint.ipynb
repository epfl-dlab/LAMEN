{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8eb97b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "75b87aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules import ChatModel, HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879bbef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f864c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "model = ChatModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89d35aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = HumanMessage(\"Hello my name is {name}\").format_prompt(\"name\",\"venia\")\n",
    "# me.format_prompt(\"name\", \"venia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b58ebefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye', 1, 2, 3]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"hi\"] + [\"bye\"] + [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dfdb671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [k.prepare_for_generation() for k in [me]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71574f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "658636ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=data,\n",
    "        temperature=0.2,\n",
    "        max_tokens=800,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49bd1ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7fn2RLeczx4bfw63tXRGuX185o7Bo at 0x7fa51b5b2d60> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"Nice to meet you, Venia! How can I assist you today?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1690194307,\n",
       "  \"id\": \"chatcmpl-7fn2RLeczx4bfw63tXRGuX185o7Bo\",\n",
       "  \"model\": \"gpt-4-0613\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 15,\n",
       "    \"prompt_tokens\": 13,\n",
       "    \"total_tokens\": 28\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8de351f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: {}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mme\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/venia/python/miniconda3/envs/venia2/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/venia/python/miniconda3/envs/venia2/lib/python3.9/site-packages/retry/api.py:73\u001b[0m, in \u001b[0;36mretry.<locals>.retry_decorator\u001b[0;34m(f, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m args \u001b[38;5;241m=\u001b[39m fargs \u001b[38;5;28;01mif\u001b[39;00m fargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m     72\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m fkwargs \u001b[38;5;28;01mif\u001b[39;00m fkwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__retry_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexceptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_delay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/venia/python/miniconda3/envs/venia2/lib/python3.9/site-packages/retry/api.py:33\u001b[0m, in \u001b[0;36m__retry_internal\u001b[0;34m(f, exceptions, tries, delay, max_delay, backoff, jitter, logger)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m _tries:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     35\u001b[0m         _tries \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/scratch/venia/socialgpt/GPTeam/src/dlabchain/modules.py:126\u001b[0m, in \u001b[0;36mChatModel.__call__\u001b[0;34m(self, messages)\u001b[0m\n\u001b[1;32m    118\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion(\n\u001b[1;32m    119\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[1;32m    120\u001b[0m     messages\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_params\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m ,response)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;241m=\u001b[39m AIMessage(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    128\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessages \u001b[38;5;241m=\u001b[39m messages\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "response = model([me])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e273878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(\"content=Hello Venia! How can I assist you today?\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eceb1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$40.02'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.estimate_cost([me], 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020adc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
